{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2c0abd51",
      "metadata": {
        "id": "2c0abd51"
      },
      "source": [
        "# Feedforward classification of the NMIST data\n",
        "### Advanced Deep Learning 2024\n",
        "This notebook was written originally Jon Sporring (mailto:sporring@di.ku.dk) and heavily inspired by https://clay-atlas.com/us/blog/2021/04/22/pytorch-en-tutorial-4-train-a-model-to-classify-mnist.\n",
        "\n",
        "We consider the Modified National Institute of Standards and Technology database of handwritten digits (MNIST): http://yann.lecun.com/exdb/mnist/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4b1cd80",
      "metadata": {
        "id": "a4b1cd80"
      },
      "source": [
        "## Installs\n",
        "\n",
        "On non-colab system, is usually good to make an environment and install necessary tools there. E.g., anaconda->jupyter->terminal create an environment, if you have not already, and activate it:\n",
        "```\n",
        "conda create -n adl python=3.9\n",
        "conda activate adl\n",
        "```\n",
        "then install missing packages such as:\n",
        "```\n",
        "conda install ipykernel torch matplotlib torchmetrics scikit-image jpeg\n",
        "conda install -c conda-forge segmentation-models-pytorch ipywidgets\n",
        "```\n",
        "and if you want to add it to jupyter's drop-down menu\n",
        "```\n",
        "ipython kernel install --user --name=adl\n",
        "```\n",
        "Now reload the jupyter-notebook's homepage and make a new or load an existing file. On colab, the tools have to be installed everytime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4afe90fa",
      "metadata": {
        "id": "4afe90fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5d8fdf6-0c51-4a71-b80d-574c6d8f5496"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cpu)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.6.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.24.0)\n",
            "Collecting segmentation-models-pytorch\n",
            "  Downloading segmentation_models_pytorch-0.3.4-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.13.1)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.36.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2024.9.20)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (0.4)\n",
            "Collecting efficientnet-pytorch==0.7.1 (from segmentation-models-pytorch)\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: huggingface-hub>=0.24.6 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.26.3)\n",
            "Collecting pretrainedmodels==0.7.4 (from segmentation-models-pytorch)\n",
            "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (1.16.0)\n",
            "Collecting timm==0.9.7 (from segmentation-models-pytorch)\n",
            "  Downloading timm-0.9.7-py3-none-any.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (0.20.1+cpu)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from segmentation-models-pytorch) (4.66.6)\n",
            "Collecting munch (from pretrainedmodels==0.7.4->segmentation-models-pytorch)\n",
            "  Downloading munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.7->segmentation-models-pytorch) (6.0.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm==0.9.7->segmentation-models-pytorch) (0.4.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (2024.8.30)\n",
            "Downloading torchmetrics-1.6.0-py3-none-any.whl (926 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m926.4/926.4 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading segmentation_models_pytorch-0.3.4-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading timm-0.9.7-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
            "Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
            "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16424 sha256=812bc1190ca978dff50da891e0affa6d4389c695a1033aed74231c0606f05623\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60944 sha256=6b58718e666d097441c584547d891fb5afa99f3f3604bd08f30ebdb7976c74fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\n",
            "Successfully built efficientnet-pytorch pretrainedmodels\n",
            "Installing collected packages: munch, lightning-utilities, torchmetrics, efficientnet-pytorch, timm, pretrainedmodels, segmentation-models-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1 lightning-utilities-0.11.9 munch-4.0.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.3.4 timm-0.9.7 torchmetrics-1.6.0\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "if IN_COLAB:\n",
        "    !pip3 install torch matplotlib torchmetrics scikit-image segmentation-models-pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0112f199",
      "metadata": {
        "id": "0112f199"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "372f3da4",
      "metadata": {
        "id": "372f3da4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as dset\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "709fa153",
      "metadata": {
        "id": "709fa153"
      },
      "source": [
        "## Set global device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef384f3a",
      "metadata": {
        "id": "ef384f3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0c9d5fa-96fd-4a05-8883-ebe544fcd9bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU State: cpu\n"
          ]
        }
      ],
      "source": [
        "# GPU\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "print('GPU State:', device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0479fa7",
      "metadata": {
        "id": "c0479fa7"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16d728ef",
      "metadata": {
        "id": "16d728ef"
      },
      "outputs": [],
      "source": [
        "def training_loop(model, loss, optimizer, loader, epochs, verbose=True, device=device):\n",
        "    \"\"\"\n",
        "    Run training of a model given a loss function, optimizer and a set of training and validation data.\n",
        "    \"\"\"\n",
        "\n",
        "    # Train\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for times, data in enumerate(loader):\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Foward + backward + optimize\n",
        "            outputs = model(inputs)\n",
        "            loss_tensor = loss(outputs, labels)\n",
        "            loss_tensor.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Print statistics\n",
        "            running_loss += loss_tensor.item()\n",
        "            if verbose:\n",
        "                if times % 100 == 99 or times+1 == len(loader):\n",
        "                    print('[%d/%d, %d/%d] loss: %.3f' % (epoch+1, epochs, times+1, len(loader), running_loss/2000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d7ce08f",
      "metadata": {
        "id": "2d7ce08f"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, loader, device=device):\n",
        "    \"\"\"\n",
        "    Evaluate a model 'model' on all batches of a torch DataLoader 'data_loader'.\n",
        "\n",
        "    Returns: the total number of correct classifications,\n",
        "             the total number of images\n",
        "             the list of the per class correct classification,\n",
        "             the list of the per class total number of images.\n",
        "    \"\"\"\n",
        "\n",
        "    # Test\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    class_correct = [0 for i in range(10)]\n",
        "    class_total = [0 for i in range(10)]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            c = (predicted == labels)\n",
        "            for i in range(len(labels)):\n",
        "                label = labels[i]\n",
        "                class_correct[label] += c[i].item()\n",
        "                class_total[label] += 1\n",
        "\n",
        "    return (correct, total, class_correct, class_total)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd353eee",
      "metadata": {
        "id": "cd353eee"
      },
      "source": [
        "## Main program"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "142ae598",
      "metadata": {
        "id": "142ae598"
      },
      "outputs": [],
      "source": [
        "# Transform\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5,), (0.5,)),]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94591bc3",
      "metadata": {
        "id": "94591bc3"
      },
      "outputs": [],
      "source": [
        "# Data\n",
        "trainSet = datasets.MNIST(root='MNIST', download=True, train=True, transform=transform)\n",
        "testSet = datasets.MNIST(root='MNIST', download=True, train=False, transform=transform)\n",
        "trainLoader = dset.DataLoader(trainSet, batch_size=64, shuffle=True)\n",
        "testLoader = dset.DataLoader(testSet, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "848e7dcc",
      "metadata": {
        "id": "848e7dcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5efd822d-3cee-47dd-df26-624d5b59b1aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNNNet(\n",
            "  (main): Sequential(\n",
            "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (4): ReLU()\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Flatten(start_dim=1, end_dim=-1)\n",
            "    (7): Linear(in_features=800, out_features=10, bias=True)\n",
            "    (8): LogSoftmax(dim=1)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Model\n",
        "class CNNNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNNet, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1)),  # Conv layer 1\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # Max pooling 1\n",
        "            nn.Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1)),  # Conv layer 2\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # Max pooling 2\n",
        "            nn.Flatten(start_dim=1, end_dim=-1),  # Flatten layer\n",
        "            nn.Linear(32 * 5 * 5, 10),  # Fully connected layer\n",
        "            nn.LogSoftmax(dim=1)  # Output layer\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.main(x)\n",
        "\n",
        "\n",
        "net = CNNNet().to(device)\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fce0735b",
      "metadata": {
        "id": "fce0735b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df60d556-7e63-41c7-9269-e6e6019085ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on 60000 images\n",
            "[1/4, 100/938] loss: 0.103\n",
            "[1/4, 200/938] loss: 0.138\n",
            "[1/4, 300/938] loss: 0.155\n",
            "[1/4, 400/938] loss: 0.168\n",
            "[1/4, 500/938] loss: 0.179\n",
            "[1/4, 600/938] loss: 0.189\n",
            "[1/4, 700/938] loss: 0.198\n",
            "[1/4, 800/938] loss: 0.207\n",
            "[1/4, 900/938] loss: 0.215\n",
            "[1/4, 938/938] loss: 0.219\n",
            "[2/4, 100/938] loss: 0.007\n",
            "[2/4, 200/938] loss: 0.014\n",
            "[2/4, 300/938] loss: 0.021\n",
            "[2/4, 400/938] loss: 0.026\n",
            "[2/4, 500/938] loss: 0.033\n",
            "[2/4, 600/938] loss: 0.038\n",
            "[2/4, 700/938] loss: 0.044\n",
            "[2/4, 800/938] loss: 0.049\n",
            "[2/4, 900/938] loss: 0.054\n",
            "[2/4, 938/938] loss: 0.056\n",
            "[3/4, 100/938] loss: 0.005\n",
            "[3/4, 200/938] loss: 0.010\n",
            "[3/4, 300/938] loss: 0.014\n",
            "[3/4, 400/938] loss: 0.019\n",
            "[3/4, 500/938] loss: 0.024\n",
            "[3/4, 600/938] loss: 0.028\n",
            "[3/4, 700/938] loss: 0.033\n",
            "[3/4, 800/938] loss: 0.037\n",
            "[3/4, 900/938] loss: 0.041\n",
            "[3/4, 938/938] loss: 0.042\n",
            "[4/4, 100/938] loss: 0.005\n",
            "[4/4, 200/938] loss: 0.008\n",
            "[4/4, 300/938] loss: 0.013\n",
            "[4/4, 400/938] loss: 0.016\n",
            "[4/4, 500/938] loss: 0.020\n",
            "[4/4, 600/938] loss: 0.024\n",
            "[4/4, 700/938] loss: 0.028\n",
            "[4/4, 800/938] loss: 0.031\n",
            "[4/4, 900/938] loss: 0.034\n",
            "[4/4, 938/938] loss: 0.036\n",
            "Training Finished.\n",
            "\n",
            "Accuracy of the network on the 10000 test images: 97 %\n",
            "Accuracy of 0: 0.987755\n",
            "Accuracy of 1: 0.992070\n",
            "Accuracy of 2: 0.984496\n",
            "Accuracy of 3: 0.987129\n",
            "Accuracy of 4: 0.979633\n",
            "Accuracy of 5: 0.977578\n",
            "Accuracy of 6: 0.982255\n",
            "Accuracy of 7: 0.971790\n",
            "Accuracy of 8: 0.967146\n",
            "Accuracy of 9: 0.963330\n"
          ]
        }
      ],
      "source": [
        "# Parameters\n",
        "epochs = 4\n",
        "lr = 0.002\n",
        "loss = nn.NLLLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.002, momentum=0.9)\n",
        "\n",
        "# Train\n",
        "print('Training on %d images' % trainSet.data.shape[0])\n",
        "training_loop(net, loss, optimizer, trainLoader, epochs)\n",
        "print('Training Finished.\\n')\n",
        "\n",
        "# Test\n",
        "correct, total, class_correct, class_total = evaluate_model(net, testLoader)\n",
        "print('Accuracy of the network on the %d test images: %d %%' % (testSet.data.shape[0], (100*correct / total)))\n",
        "for i in range(10):\n",
        "    print('Accuracy of %d: %3f' % (i, (class_correct[i]/class_total[i])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f06850a",
      "metadata": {
        "id": "7f06850a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "display_name": "adl",
      "language": "python",
      "name": "adl"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}